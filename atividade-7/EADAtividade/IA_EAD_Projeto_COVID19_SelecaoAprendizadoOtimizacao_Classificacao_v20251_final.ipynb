{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red' size='6'>Inteligência Artificial</font>\n",
    "### Atividade: Previsão de óbito por COVID-19\n",
    "<font color='red' size='4'><b>Problema de Negócio</b></font>: Com base nos dados obtidos de (1), o problema de negócio é: prever se uma pessoa pode vir a óbito ou não por COVID-19.\n",
    "\n",
    "(1) COVID-19 Mexico Patient Health Dataset. (2020, 05 19). Disponível em Kaggle.com: https://www.kaggle.com/riteshahlawat/covid19-mexico-patient-health-dataset . Data da consulta: 15 de março de 2025.\n",
    "\n",
    "Fonte: YAVUZ, Ü. N. A. L.; DUDAK, Muhammed Nuri. Classification of Covid-19 Dataset with Some Machine Learning Methods. Journal of Amasya University the Institute of Sciences and Technology, v. 1, n. 1, p. 30-37. Disponível em: https://dergipark.org.tr/en/pub/jauist/issue/55760/748667. Data da Consulta: 15 de Marco de 2025.\n",
    " \n",
    "<font color='red' size='4'><b>Etapas: Seleção de Atributos. Aprendizado: Aplicação dos Algoritmos, Avaliação, Geração de Modelos Preditivos, Otimização e Validação</b></font>\n",
    "\n",
    "Descrição: \n",
    "<ol>\n",
    "    <li>Dataset \" df_covid_preparados.csv \" contendo 95839 casos de COVID-19 que são formados por 19 atributos e registrados pelo governo mexicano entre 15 de janeiro de 2020 e 3 de maio de 2020 para dados sobre a doença de Covid-19.</li>\n",
    "<li>Notebook “IA_EAD_Projeto_COVID19_SelecaoAprendizadoOtimizacao_Classificacao_v20242.ipynb” que deve ser executado com o dataset do grupo indicado no item 1 desta atividade. Não se esqueça de separar 10 dados, sendo 5 com óbito e 5 sem óbito para permitir os testes. Esses 10 dados devem ser gravados em um dataset que será utilizado para validação ao final do notebook.</li>\n",
    "<li>Modelo preditivo obtido no item 2: o modelo preditivo gerado: “modelo_METODO_class_obitoCOVID_GRUPO.sav”, encontrado a partir da execução do Notebook do item 2. Não se esqueça de alterar a parte do arquivo com o nome do grupo, indicado por vocês e o nome do MÉTODO</li>\n",
    "<li>A partir do modelo gerado, realizar os testes solicitados com os 10 dados separados e montar uma tabela HTML na qual consta os resultados.</li>   \n",
    "<li>Após obter os resultados, discuta-os. Por exemplo, apresente os aspectos positivos e limitações do modelo, tendo por base o relatório de métricas/matriz de confusão do modelo otimizado e os resultados obtidos com os 10 dados de validação.</li>\n",
    "</ol>\n",
    "\n",
    "### <font color=\"black\" size='3'><b>Grupo em ordem alfabética (máx. 3 alunos) </b></font>\n",
    "<html>\n",
    "<table border=\"1px\">\n",
    "<tr>\n",
    "<td bgcolor=\"Aquamarine\">Nome do Aluno</td>\n",
    "<td bgcolor=\"Aquamarine\">RA</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td bgcolor=\"white\">nome 1</td>\n",
    "<td bgcolor=\"white\">RA 1</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td bgcolor=\"white\">nome 2</td>\n",
    "<td bgcolor=\"white\">RA 2</td>\n",
    "</tr>\n",
    "    <tr>\n",
    "<td bgcolor=\"white\">nome 3</td>\n",
    "<td bgcolor=\"white\">RA 3</td>\n",
    "</tr>\n",
    "    </table>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# ignora os warnings \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Por se tratar de um conjunto de gráficos menores, pode ser mais interessante gerar os gráficos em janela separada\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise Exploratória: Síntese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura do arquivo CSV com separador \",\" e codificação UTF-8\n",
    "# COVID-19 Mexico Patient Health Dataset. (2020, 05 19). Retrieved \n",
    "# from Kaggle.com: https://www.kaggle.com/riteshahlawat/covid19-mexico-patient-health-dataset\n",
    "df_covid = pd.read_csv('df_covid_preparados.csv', sep = ',', encoding = 'UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra dois registros do arquivo\n",
    "df_covid.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apresenta os tipas de dados das colunas\n",
    "df_covid.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra o shape do dataset\n",
    "df_covid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mostra a frequência absoluta de  registros do atributo sexo (intervalo: [1,2]), onde:\n",
    "# 1- Mulher, 2- homem  \n",
    "df_covid.groupby(\"sexo\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra a frequência absoluta de  registros do atributo tipo_paciente (intervalo: [1,2]), onde:\n",
    "# Tipo 1, Tipo 2 \n",
    "df_covid.groupby(\"tipo_paciente\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra a frequência absoluta  de  registros do atributo intubado (intervalo: [1,99]), onde: \n",
    "# 1 = Sim, 2 = Não, 98/97: Não se aplica, 99: Não disponível. \n",
    "df_covid.groupby(\"intubado\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra a frequência absoluta  de  registros do atributo pneumonia (intervalo: [1,99]), onde: \n",
    "# 1 = Sim, 2 = Não, 98/97: Não se aplica, 99: Não disponível. \n",
    "df_covid.groupby(\"pneumonia\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresenta o histograma do atributo idade. Observe a distribuição e os picos.\n",
    "# Considere bins como sendo o número de barras\n",
    "df_covid.idade.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra a frequência absoluta de  registros do atributo gravidez (intervalo: [1,98]), onde: \n",
    "# 1 = Sim, 2 = Não, 98/97: Não se aplica. \n",
    "df_covid.groupby(\"gravidez\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra a frequência absoluta de  registros do atributo diabetes (intervalo: [1,98]), onde: \n",
    "# 1 = Sim, 2 = Não, 98/97: Não se aplica. \n",
    "df_covid.groupby(\"diabetes\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra a frequência absoluta de  registros do atributo copd (intervalo: [1,98]), onde: \n",
    "# 1 = Sim, 2 = Não, 98/97: Não se aplica. \n",
    "# copd = doença pulmonar obstrutiva crônica \n",
    "df_covid.groupby(\"copd\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra a frequência absoluta de  registros do atributo asma (intervalo: [1,98]), onde: \n",
    "# 1 = Sim, 2 = Não, 98/97: Não se aplica. \n",
    "df_covid.groupby(\"asma\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra a frequência absoluta de  registros do atributo imunossupressao (intervalo: [1,98]), onde: \n",
    "# 1 = Sim, 2 = Não, 98/97: Não se aplica. \n",
    "df_covid.groupby(\"imunossupressao\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra oa frequência absoluta de  registros do atributo hipertensao (intervalo: [1,98]), onde: \n",
    "# 1 = Sim, 2 = Não, 98/97: Não se aplica. \n",
    "df_covid.groupby(\"hipertensao\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra a frequência absoluta de  registros do atributo outras_doencas (intervalo: [1,98]), onde: \n",
    "# 1 = Sim, 2 = Não, 98/97: Não se aplica. \n",
    "df_covid.groupby(\"outras_doencas\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra a frequência absoluta de  registros do atributo cardiovascular (intervalo: [1,98]), onde: \n",
    "# 1 = Sim, 2 = Não, 98/97: Não se aplica. \n",
    "df_covid.groupby(\"cardiovascular\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra a frequência absoluta de  registros do atributo obesidade (intervalo: [1,98]), onde: \n",
    "# 1 = Sim, 2 = Não, 98/97: Não se aplica. \n",
    "df_covid.groupby(\"obesidade\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra a frequência absoluta de  registros do atributo irc (intervalo: [1,98]), onde: \n",
    "# 1 = Sim, 2 = Não, 98/97: Não se aplica. \n",
    "# irc = insuficiência renal crônica\n",
    "df_covid.groupby(\"irc\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra a frequência absoluta de  registros do atributo fumante (intervalo: [1,98]), onde: \n",
    "# 1 = Sim, 2 = Não, 98/97: Não se aplica. \n",
    "df_covid.groupby(\"fumante\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra a frequência absoluta de  registros do atributo outro_caso (intervalo: [1,98]), onde: \n",
    "# 1 = Sim, 2 = Não, 98/97: Não se aplica. \n",
    "df_covid.groupby(\"outro_caso\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra a frequência absoluta de  registros do atributo teste_covid (intervalo: [1,3]), onde: \n",
    "# 1 = COVID-19 Positivo, 2 = COVID-19 Negativo, 3 = Não se aplica. \n",
    "df_covid.groupby(\"teste_covid\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra a frequência absoluta de  registros do atributo icu (intervalo: [1,99]), onde: \n",
    "# 1 = Sim, 2 = Não, 98/97: Não se aplica, 99 - Não disponivel. \n",
    "# uci = unidade de terapia intensiva\n",
    "df_covid.groupby(\"icu\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra a frequência absoluta de  registros do atributo obito (intervalo: [0,1]), onde: \n",
    "# 1 = Sim, 2 = Não.\n",
    "df_covid.groupby(\"obito\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo estatístico do dataset completo\n",
    "df_covid.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo estatístico dos que faleceram\n",
    "df_covid[df_covid.obito == 1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo estatístico dos que sobrevireram\n",
    "df_covid[df_covid.obito == 0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtém a frequência absoluta de pessoas com pneumonia\n",
    "serie_pneumonia = df_covid.groupby(\"pneumonia\").size()\n",
    "\n",
    "# coloca \"explode\" com 0 em todos os índices, exceção o índece 0 com o valor 0.2\n",
    "explode = tuple(0 if i != 0 else 0.2 for i in range(serie_pneumonia.size))\n",
    "\n",
    "plt.pie(serie_pneumonia.values, explode=explode, labels=serie_pneumonia.index, \n",
    "        autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "# equal garante que o gráfico seja desenhado como um círculo. \n",
    "plt.axis('equal')\n",
    "plt.title(\"Com Pneumonia (1) x Sem Pneumonia (2)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A correlação é o relacionamento entre 2 variáveis. O método mais comum para calcular correlação é o método de Pearson, que assume uma distribuição normal dos dados. Correlação de -1 mostra uma correlação negativa, enquanto uma correlação de +1 mostra uma correlação positiva. Uma correlação igual a 0 mostra que não há relacionamento entre as variáveis.\n",
    "\n",
    "Alguns algoritmos como regressão linear e regressão logística podem apresentar problemas de performance se houver atributos altamente correlacionados (colineares)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria mapa de calor com a correlação do dataset com o mapa ce cores PiYG\n",
    "# Aumenta o tamanho da figura a ser exibida\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(df_covid.corr(), annot=True, cmap = \"PiYG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método Ensemble para Seleção de Variáveis\n",
    "\n",
    "Documentação: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html.\n",
    "        \n",
    "Bagged Decision Trees, como o algoritmo RandomForest (são chamados de Métodos Ensemble), podem ser usados para estimar a importância de cada atributo. \n",
    "\n",
    "Esse método retorna um score para cada atributo.\n",
    "\n",
    "Quanto maior o score, maior a importância do atributo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importância do Atributo com o RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dos Módulos\n",
    "from pandas import read_csv\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura do arquivo CSV com separador \",\" e codificação UTF-8\n",
    "# COVID-19 Mexico Patient Health Dataset. (2020, 05 19). Retrieved \n",
    "# from Kaggle.com: https://www.kaggle.com/riteshahlawat/covid19-mexico-patient-health-dataset\n",
    "df_covid = pd.read_csv('df_covid_preparados.csv', sep = ',', encoding = 'UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra as colunas do dataset\n",
    "df_covid.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtdeColunas = len(df_covid.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando os dados\n",
    "array = df_covid.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando o array em componentes de entrada (atributos preditivos) e output (atributo alvo)\n",
    "X = array[:,0:qtdeColunas-1] # Atributos Preditores selecionados de 1 a 5 (exclusivo)\n",
    "Y = array[:,qtdeColunas-1] # Atributo alvo: severity (1 - maligno, 0 - benigno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação do Modelo - Feature Selection\n",
    "modelo = RandomForestClassifier()\n",
    "modelo.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monta uma série contendo os nomes dos atributos e a sua importância \n",
    "sAtributos = pd.Series(modelo.feature_importances_, index=df_covid.columns[0:qtdeColunas-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra a importância dos atributos\n",
    "# Considerando este fato, podemos selecionar os mais relevantes\n",
    "# Claro que podemos utilizar o nosso conhecimento sobre o assunto\n",
    "sAtributos.sort_values(ascending=False)[0:qtdeColunas-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANTE:\n",
    "# FAÇA AQUI A SELEÇÃO DE ATRIBUTOS E GRAVE O DATASET \n",
    "# Montando o dataset com os atributos preditores selecionados\n",
    "# e o atributo alvo MODIFIQUE O ELABORADO ABAIXO.\n",
    "dfcovid_SPAtribSelec = df_covid[[\"idade\", \"intubado\", \"teste_covid\", \"outro_caso\", \"icu\", \"pneumonia\", \"obesidade\", \"hipertensao\", \"diabetes\", \"fumante\",\"obito\"]];\n",
    "dfcovid_SPAtribSelec.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando os atributos preparados\n",
    "dfcovid_SPAtribSelec.to_csv(\"dfcovid_atrib_selec.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset de validação\n",
    "<p>A partir do dataset com os atributos selecionados anteriormente \"dfcovid_atrib_selec.csv\", separe 10 dados do dataset, sendo 5 COM ÓBITO e 5 SEM ÓBITO. Esses dados serão utilizadso na validação final.<br>\n",
    "<p>CUIDADO! A seleção deve ser aleatória e pode ser feita diretamente (manualmente) no arquivo do CSV. O nome do arquivo de dados de validação pode ser \"dfcovid_atrib_selec_valida.csv\".<br>\n",
    "<p>Lembrando que esses dados serão utilizados na etapa de validação ao final deste notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dos Módulos\n",
    "from pandas import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leia o dataset de validação "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validacao = pd.read_csv('dfcovid_atrib_selec_valida.csv', sep = ',', encoding = 'UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresente o seu conteúdo com df_validacao.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validacao.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizado Supervisionado: Algoritmos de Classificação\n",
    "\n",
    "Não há como saber qual algoritmo vai funcionar melhor na construção do modelo, antes de realizar os testes do algoritmo com os dados de testes do </i>dataset</i>. \n",
    "\n",
    "O ideal é testar alguns algoritmos e então escolher aquele que fornece melhor nível de precisão. \n",
    "\n",
    "Para isso, serão considerados os algoritmos de classificação:\n",
    "\n",
    "1) <i>K-Nearest Neighbors</i> (KNN)<br />\n",
    "Documentação: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html.\n",
    "\n",
    "2) Árvore de Decisão (CART - <i>Classification and Regression Trees</i>) <br />\n",
    "Documentação: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.\n",
    "\n",
    "3) Regressão Logística <br />\n",
    "Documentação: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html.\n",
    "\n",
    "4) Naïve Bayes<br />\n",
    "Documentação: https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html.\n",
    "\n",
    "5) Máquinas de Vetores de Suporte (SVMs - <i>Support Vector Machines</i>)<br />\n",
    "Documentação: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html.\n",
    "\n",
    "6) Random Forest<br />\n",
    "Documentação: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html.\n",
    "\n",
    "7) AdaBoost<br />\n",
    "Documentação: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html.\n",
    "\n",
    "Todos os sete algoritmos serão utilizados juntos com os mesmos dados de treino e teste.\n",
    "\n",
    "A métrica de comparação utilizada será acurácia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados de Treino e de Teste\n",
    "\n",
    "Documentação: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "Este é o método mais utilizado para avaliar performance de um algoritmo de Machine Learning. \n",
    "\n",
    "Dividimos nossos dados originais em dados de treino e de teste. \n",
    "\n",
    "Treinamos o algoritmo nos dados de treino e fazemos as previsões nos dados de teste e avaliamos o resultado. \n",
    "\n",
    "A divisão dos dados vai depender do seu dataset, mas utiliza-se com frequência tamanhos entre 80/20 (treino/teste) e 70/30 (treino/teste).\n",
    "\n",
    "Este método é bem veloz e ideal para conjuntos de dados muito grandes. \n",
    "\n",
    "O ponto negativo é a possibilidade de alta variância."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliando a Performance\n",
    "\n",
    "\n",
    "As métricas que você escolhe para avaliar a performance do modelo vão influenciar a forma como a performance é medida e comparada com modelos criados com outros algoritmos.\n",
    "\n",
    "Vamos utilizar o mesmo algoritmo, mas com métricas diferentes e assim comparar os resultados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas para Algoritmos de Classificação\n",
    "\n",
    "Documentação: https://scikit-learn.org/stable/modules/model_evaluation.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dos módulos\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Importando os módulos dos algoritmos\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura do arquivo CSV com separador \",\" e codificação UTF-8\n",
    "# COVID-19 Mexico Patient Health Dataset. (2020, 05 19). Retrieved \n",
    "# from Kaggle.com: https://www.kaggle.com/riteshahlawat/covid19-mexico-patient-health-dataset\n",
    "df_covid = pd.read_csv('dfcovid_atrib_selec<SEM DADOS DE VALIDAÇÃO>.csv', sep = ',', encoding = 'UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtém os dados do câncer de mama\n",
    "array = df_covid.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtdeColunas = len(df_covid.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando o array em componentes de entrada (atributos preditivos) e output (atributo alvo)\n",
    "X = array[:,0:qtdeColunas-1] # Atributos Preditores selecionados de 0 a qtdeColunas (exclusivo)\n",
    "Y = array[:,qtdeColunas-1] # Atributo alvo: obito (1 - sim, 0 - não)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo o tamanho das amostras\n",
    "teste_size = 0.3\n",
    "\n",
    "# Garante que os resultados podem ser reproduzidos\n",
    "# Isso é importante para comparar a acurácia com outros algoritmos de Machine Learning.\n",
    "seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando os conjuntos de dados de treino e de teste\n",
    "X_treino, X_teste, Y_treino, Y_teste = train_test_split(X, Y, test_size = teste_size, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparando a lista de modelos instanciados\n",
    "modelos = []\n",
    "modelos.append(('KNN', KNeighborsClassifier()))\n",
    "modelos.append(('CART', DecisionTreeClassifier()))\n",
    "modelos.append(('LR', LogisticRegression()))\n",
    "modelos.append(('NB', GaussianNB()))\n",
    "modelos.append(('SVM', SVC()))\n",
    "modelos.append(('RFor', RandomForestClassifier()))\n",
    "modelos.append(('AdaB', AdaBoostClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliando cada modelo em um loop\n",
    "dicAcuracia = {}\n",
    "dicMatriz = {}\n",
    "dicRelatorio = {}\n",
    "\n",
    "for nome, modelo in modelos:\n",
    "    # Treinamento do modelo\n",
    "    modelo.fit(X_treino, Y_treino)\n",
    "    # Fazendo as previsões e construindo a Matriz de Confusão\n",
    "    previsoes = modelo.predict(X_teste)\n",
    "    # Obtendo a matriz de confusão\n",
    "    matrix = confusion_matrix(Y_teste, previsoes)\n",
    "    # construindo o relatório de resultados\n",
    "    report = classification_report(Y_teste, previsoes)\n",
    "    # Score do modelo nos dados de teste  (Acurácia)\n",
    "    acuracia = modelo.score(X_teste, Y_teste)\n",
    "    # Criando dicionários para a acurácia matriz de confusão e relatório\n",
    "    dicAcuracia[nome] = acuracia*100.0\n",
    "    dicMatriz[nome] = matrix\n",
    "    dicRelatorio[nome] = report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montando um dataframe com a acurácia obtida de cada modelo\n",
    "pdAcuraciaModelos = pd.DataFrame(dicAcuracia.items())\n",
    "pdAcuraciaModelos.columns = ['nome','acuracia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresenta a acurácia dos modelos ordenados\n",
    "pdAcuraciaModelos.sort_values(ascending=False, by='acuracia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos.append(('KNN', KNeighborsClassifier()))\n",
    "modelos.append(('CART', DecisionTreeClassifier()))\n",
    "modelos.append(('LR', LogisticRegression()))\n",
    "modelos.append(('NB', GaussianNB()))\n",
    "modelos.append(('SVM', SVC()))\n",
    "modelos.append(('RFor', RandomForestClassifier()))\n",
    "modelos.append(('AdaB', AdaBoostClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresenta a matriz de confusão para o KNN\n",
    "dicMatriz['KNN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresenta a matriz de confusão para o CART\n",
    "dicMatriz['CART']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresenta a matriz de confusão para o Regressão Logística\n",
    "dicMatriz['LR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresenta a matriz de confusão para o Naive Bayes\n",
    "dicMatriz['NB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresenta a matriz de confusão para o SVM\n",
    "dicMatriz['SVM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresenta a matriz de confusão para o Random Forest\n",
    "dicMatriz['RFor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresenta a matriz de confusão para o Random Forest\n",
    "dicMatriz['AdaB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de barras para comparar a acurácia entre os modelos\n",
    "plt.bar(list(dicAcuracia.keys()), dicAcuracia.values(), color='red')\n",
    "# legenda do eixo x\n",
    "plt.xticks(list(dicAcuracia.keys()))\n",
    "# Label eixo Y\n",
    "plt.ylabel('Acurácia')\n",
    "# Label eixo X\n",
    "plt.xlabel('Classificador')\n",
    "# Título do gráfico\n",
    "plt.title('Classificador x Acurácia')\n",
    "# mostra o gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Otimização do Modelo - Ajuste de Hyperparâmetros\n",
    "<font color='red' size='4'><b>Escolha um algoritmo para realizar o ajuste de parâmetros</b></font>\n",
    "\n",
    "Todos os algoritmos de Aprendizado de Máquina são parametrizados, o que significa que você pode ajustar a performance do seu modelo preditivo, através do <i>tuning</i> (ajuste fino) dos parâmetros. \n",
    "\n",
    "Seu trabalho é encontrar a melhor combinação entre os parâmetros em cada algoritmo de Aprendizado de Máquina. \n",
    "\n",
    "Esse processo também é chamado de Otimização Hyperparâmetro. \n",
    "\n",
    "O scikit-learn oferece dois métodos para otimização automática dos parâmetros: <i>Grid Search Parameter Tuning</i> e <i>Random Search Parameter Tuning</i>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Search Parameter Tuning\n",
    "\n",
    "Documentação: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html.\n",
    "\n",
    "Este método gera amostras dos parâmetros dos algoritmos a partir de uma distribuição randômica uniforme para um número fixo de interações. \n",
    "\n",
    "Um modelo é construído e testado para cada combinação de parâmetros.\n",
    "\n",
    "Vamos experimentar este método utilizando algum algoritmo do seu interesse ou aquele que obteve melhor acurácia. \n",
    "\n",
    "Será necessário identificar os parâmetros do algoritmo, fornecer variações nos parâmetros e obter os melhores resultados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dos módulos\n",
    "import numpy as np\n",
    "\n",
    "# Uma variável aleatória contínua uniforme.\n",
    "# No formulário padrão, a distribuição é uniforme em [0, 1]. \n",
    "# Usando os parâmetros loc e scale, obtém-se a distribuição uniforme em [loc, loc + scale].\n",
    "from scipy.stats import uniform\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Importando o módulo do algoritmo selecionado\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura do arquivo CSV com separador \",\" e codificação UTF-8\n",
    "# COVID-19 Mexico Patient Health Dataset. (2020, 05 19). Retrieved \n",
    "# from Kaggle.com: https://www.kaggle.com/riteshahlawat/covid19-mexico-patient-health-dataset\n",
    "df_covid = pd.read_csv('dfcovid_atrib_selec.csv', sep = ',', encoding = 'UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtém os dados\n",
    "array = df_covid.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtdeColunas = len(df_covid.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando o array em componentes de entrada (atributos preditivos) e output (atributo alvo)\n",
    "X = array[:,0:qtdeColunas-1] # Atributos Preditores selecionados de 0 a qtdeColunas (exclusivo)\n",
    "Y = array[:,qtdeColunas-1] # Atributo alvo: obito (1 - sim, 0 - não)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo os valores que serão testados\n",
    "# n_estimators (int), default = 50\n",
    "#      O número máximo de estimadores em que o reforço é encerrado. \n",
    "#      Em caso de ajuste perfeito, o processo de aprendizagem é interrompido precocemente.\n",
    "# learning_rate (float), default = 1.\n",
    "#      A taxa de aprendizagem reduz a contribuição de cada classificador por learning_rate. \n",
    "#      Há uma compensação entre learning_rate e n_estimators.\n",
    "# algorithm {‘SAMME’, ‘SAMME.R’}, padrão = ’SAMME.R’ (NÃO VAMOS UTILIZAR)\n",
    "#      Se 'SAMME.R', então use o algoritmo real de boosting SAMME.R. \n",
    "#      base_estimator deve oferecer suporte ao cálculo de probabilidades de classe. \n",
    "#      Se 'SAMME', então use o algoritmo de aumento discreto SAMME. \n",
    "#      O algoritmo SAMME.R normalmente converge mais rápido do que SAMME, \n",
    "#      alcançando um erro de teste menor com menos iterações de reforço.\n",
    "# random_state (int) ou RandomState, default = None\n",
    "#      Controla a semente aleatória fornecida em cada base_estimator em cada iteração de reforço. \n",
    "#      Portanto, ele só é usado quando base_estimator expõe um random_state. \n",
    "#      Passe um int para saída reproduzível em várias chamadas de função. \n",
    "valores_grid = { <DEFINIR AQUI O RANGE DOS HIPERPARÂMETROS A SER FEITA A BUSCA PELOS MELHORRES VALORES - pelo menos 2> }\n",
    "seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando o modelo que será utilizado SEGUNDO OS RESULTADOS OBTIDOS ANTERIORMENTE\n",
    "modelo = <DEFINIR AQUI O MODELO A SER OTIMIZADO OS HIPERPARÂMETROS>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancia o método para procura dos melhores hiperparâmetros\n",
    "# com A QUANTIDADE DE ITERAÇÕES definidas por você (>= 200)\n",
    "iterations = <DEFINIR A QUANTIDADE AQUI >= 200>\n",
    "rsearch = RandomizedSearchCV(estimator = modelo, \n",
    "                             param_distributions = valores_grid, \n",
    "                             n_iter = iterations, \n",
    "                             random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz o fit para encontrar os melhores valores para os parâmetros\n",
    "rsearch.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print do resultado\n",
    "print(\"Melhores Parâmetros do Modelo:\\n\", rsearch.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo o tamanho das amostras\n",
    "teste_size = 0.2\n",
    "\n",
    "# Garante que os resultados podem ser reproduzidos\n",
    "# Isso é importante para comparar a acurácia com outros algoritmos de Machine Learning.\n",
    "seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando os conjuntos de dados de treino e de teste\n",
    "X_treino, X_teste, Y_treino, Y_teste = train_test_split(X, Y, test_size = teste_size, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o objeto que vai obter o modelo COM OS MELHORES HIPERPARÂMETROS SELECIONADOS \n",
    "modelo = <COLOQUE AQUI O MODELO COM OS MELHORES HIPERPARÂMETROS SELECIONADOS>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do modelo\n",
    "modelo.fit(X_treino, Y_treino)\n",
    "\n",
    "# Fazendo as previsões e construindo a Matriz de Confusão\n",
    "previsoes = modelo.predict(X_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendo a matriz de confusão\n",
    "matrix = confusion_matrix(Y_teste, previsoes)\n",
    "\n",
    "# construindo o relatório de resultados\n",
    "report = classification_report(Y_teste, previsoes)\n",
    "\n",
    "# Score do modelo nos dados de teste  (Acurácia)\n",
    "result = modelo.score(X_teste, Y_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Imprime os resultados\n",
    "print(\"Acurácia nos Dados de Teste: %.3f%%\" % (result * 100.0))\n",
    "\n",
    "# Imprimindo a Matriz de Confusão\n",
    "print(matrix)\n",
    "\n",
    "# Imprimindo o relatório\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><B>Questão a ser respondida</B></P>\n",
    "<p> Reflita sobre os resultados obtidos com o relatório de medidas de performance do modelo e sua matriz de confusão e discuta-os (Sugestão: considere as métricas, matriz de confusão e cada classe individualmente) </P>\n",
    "<P> Resposta: COLOQUE AQUI A DISCUSSÃO SOLICITADA </P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvando o modelo\n",
    "\n",
    "O modelo deve ser obtido pelo algoritmo utilizado na etapa anterior, otimização do modelo, com os melhores valores para os seus hiperparâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dos módulos\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Importando o módulo do algoritmo selecionado\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Importando o pacote utilizado para salvar o modelo como arquivo binário\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura do arquivo CSV com separador \",\" e codificação UTF-8\n",
    "# COVID-19 Mexico Patient Health Dataset. (2020, 05 19). Retrieved \n",
    "# from Kaggle.com: https://www.kaggle.com/riteshahlawat/covid19-mexico-patient-health-dataset\n",
    "df_covid = pd.read_csv('dfcovid_atrib_selec.csv', sep = ',', encoding = 'UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando os dados\n",
    "array = df_covid.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtdeColunas = len(df_covid.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando o array em componentes de entrada (atributos preditivos) e output (atributo alvo)\n",
    "X = array[:,0:qtdeColunas-1] # Atributos Preditores selecionados de 0 a qtdeColunas (exclusivo)\n",
    "Y = array[:,qtdeColunas-1] # Atributo alvo: obito (1 - sim, 0 - não)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo o tamanho das amostras\n",
    "teste_size = 0.2\n",
    "\n",
    "# Garante que os resultados podem ser reproduzidos\n",
    "# Isso é importante para comparar a acurácia com outros algoritmos de Machine Learning.\n",
    "seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando os conjuntos de dados de treino e de teste\n",
    "X_treino, X_teste, Y_treino, Y_teste = train_test_split(X, Y, test_size = teste_size, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o objeto que vai obter o modelo \n",
    "#  Fazendo uso dos melhores valores dos parâmetros obtidos com o RandomizeSearchCV\n",
    "modelo = <COLOQUE AQUI O MODELO COM OS MELHORES HIPERPARÂMETROS SELECIONADOS>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do modelo\n",
    "modelo.fit(X_treino, Y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar O NOME DO ARQUIVO do modelo, compatível com o algoritmo escolhido.\n",
    "arquivo = 'modelo_METODO_class_obitoCOVID_GRUPO.sav'\n",
    "joblib.dump(modelo, arquivo)\n",
    "print(\"Modelo salvo!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o arquivo\n",
    "modelo_class_final = joblib.load(arquivo)\n",
    "print(\"Modelo carregado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo previsões\n",
    "Y_pred = modelo_class_final.predict(X_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendo a matriz de confusão\n",
    "matrix = confusion_matrix(Y_teste, Y_pred); matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score do modelo nos dados de teste  (Acurácia)\n",
    "result = modelo_class_final.score(X_teste, Y_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime os resultados\n",
    "print(\"Acurácia nos Dados de Teste: %.3f%%\" % (result * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realizando a validação\n",
    "\n",
    "A partir do modelo otimizado, faça a validação com os 10 dados de validação separados. Depois, monte um quadro com os resultados e discuta-os neste notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte um quadro com os resultados obtidos para os 10 dados de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coloque o quadro aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discuta os resultados obtidos com a validação (compare com as métricas e matriz de confusão, indique limitações e vantagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discuta abaixo os reultados da validação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font size = '2'>prof. Dr. Ivan Carlos Alcântara de Oliveira</font> - <font color=\"blue\" size = '2'>https://orcid.org/0000-0002-6020-7535.</font><br><font size = '2'> e-mail: ivan.oliveira@mackenzie.br</font>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
